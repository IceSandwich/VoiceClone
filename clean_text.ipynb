{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 1205\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "dataset: typing.List[typing.Tuple[str, str]] = []\n",
    "with open(\"assets/text/mandarin_train.txt\", \"r\", encoding='utf-8') as f:\n",
    "\tlines = f.readlines()\n",
    "\tfor i in range(0, len(lines), 2):\n",
    "\t\tline = lines[i].strip().strip('\\n')\n",
    "\t\tif line == \"\": continue\n",
    "\t\tphome = lines[i+1].strip().strip('\\n')\n",
    "\t\tdataset.append((line, phome))\n",
    "print(f\"dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('躺在急救担架上的男子双目紧闭，头发散发出一股烧焦的味道。',\n",
       "  'tang3 zai4 ji2 jiu4 dan1 jia4 shang4 de5 nan2 zi3 shuang1 mu4 jin3 bi4 tou2 fa4 san4 fa1 chu1 yi4 gu3 shao1 jiao1 de5 wei4 dao4'),\n",
       " ('工业园区是承接产业转移、加速产业集聚、培育产业集群的主要载体。',\n",
       "  'gong1 ye4 yuan2 qu1 shi4 cheng2 jie1 chan3 ye4 zhuan3 yi2 jia1 su4 chan3 ye4 ji2 ju4 pei2 yu4 chan3 ye4 ji2 qun2 de5 zhu3 yao4 zai4 ti3'),\n",
       " ('那一刻，我才真正的懂你，就像懂我现在的自己。',\n",
       "  'na4 yi2 ke4 wo3 cai2 zhen1 zheng4 de5 dong2 ni3 jiu4 xiang4 dong2 wo3 xian4 zai4 de5 zi4 ji3'),\n",
       " ('由于列车长时间停靠，车厢内的空气越来越“闷”。',\n",
       "  'you2 yu2 lie4 che1 zhang3 shi2 jian1 ting2 kao4 che1 xiang1 nei4 de5 kong1 qi4 yue4 lai2 yue4 men1'),\n",
       " ('但如果按车队规模，一嗨数千辆车的量级绝对算不上最大。',\n",
       "  'dan4 ru2 guo3 an4 che1 dui4 gui1 mo2 yi4 hai1 shu4 qian1 liang4 che1 de5 liang4 ji2 jue2 dui4 suan4 bu2 shang4 zui4 da4')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba, pypinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calpinyin_str(text: str):\n",
    "\tcuts = list(jieba.cut(text))\n",
    "\tpinyin = []\n",
    "\tfor cut in cuts:\n",
    "\t\tif cut in [\"，\", \"。\", \"\\\"\", \"”\", \"“\", \"、\",\"？\",\"！\", \"；\",\"：\"]: continue\n",
    "\t\tpy = pypinyin.lazy_pinyin(cut, style=pypinyin.Style.TONE3, tone_sandhi=True)\n",
    "\t\tfor x in py:\n",
    "\t\t\tpinyin.append(x)\n",
    "\treturn ' '.join(pinyin).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to fixed: 970\n",
      "auto fixed: 172\n"
     ]
    }
   ],
   "source": [
    "need_to_fixed: typing.List[typing.Tuple[int, str]] = []\n",
    "auto_fixed: typing.List[typing.Tuple[int, str]] = []\n",
    "for i, (text, phome) in enumerate(dataset):\n",
    "\tpinyin_str = calpinyin_str(text)\n",
    "\tif pinyin_str != phome:\n",
    "\t\tsource_pinyin = dataset[i][1].split(' ')\n",
    "\t\tpinyin = pinyin_str.split(' ')\n",
    "\t\tcan_auto_fix = True\n",
    "\t\ttarget_pinyin = []\n",
    "\t\tif len(source_pinyin) == len(pinyin):\n",
    "\t\t\tfor k in range(len(source_pinyin)):\n",
    "\t\t\t\tif source_pinyin[k]== pinyin[k]:\n",
    "\t\t\t\t\ttarget_pinyin.append(source_pinyin[k])\n",
    "\t\t\t\telif source_pinyin[k].startswith(pinyin[k]) and source_pinyin[k][len(pinyin[k]):] in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "\t\t\t\t\ttarget_pinyin.append(pinyin[k])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcan_auto_fix = False\n",
    "\t\t\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tcan_auto_fix = False\n",
    "\t\t\t\n",
    "\t\tif can_auto_fix:\n",
    "\t\t\tauto_fixed.append((i, ' '.join(target_pinyin)))\n",
    "\t\telse:\n",
    "\t\t\tneed_to_fixed.append((i, pinyin_str))\n",
    "print(f\"need to fixed: {len(need_to_fixed)}\")\n",
    "print(f\"auto fixed: {len(auto_fixed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "躺在急救担架上的男子双目紧闭，头发散发出一股烧焦的味道。\n",
      "Pinyin:\n",
      "tang3 zai4 ji2 jiu4 dan1 jia4 shang4 de nan2 zi shuang1 mu4 jin3 bi4 tou2 fa4 san4 fa4 chu1 yi1 gu3 shao1 jiao1 de wei4 dao4\n",
      "Source:\n",
      "tang3 zai4 ji2 jiu4 dan1 jia4 shang4 de5 nan2 zi3 shuang1 mu4 jin3 bi4 tou2 fa4 san4 fa1 chu1 yi4 gu3 shao1 jiao1 de5 wei4 dao4\n"
     ]
    }
   ],
   "source": [
    "showindex = 0\n",
    "showlist = need_to_fixed\n",
    "print(dataset[showlist[showindex][0]][0])\n",
    "print(\"Pinyin:\")\n",
    "print(showlist[showindex][1])\n",
    "print(\"Source:\")\n",
    "print(dataset[showlist[showindex][0]][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for (line_number, pinyin_str) in need_to_fixed:\n",
    "\tsource = dataset[line_number][1].split(' ')\n",
    "\tpinyin = pinyin_str.split(' ')\n",
    "\tif len(source) == len(pinyin):\n",
    "\t\tfor i in range(len(source)):\n",
    "\t\t\tif source[i]!= pinyin[i]:\n",
    "\t\t\t\tif source[i].startswith(pinyin[i]) and source[i][len(pinyin[i]):] in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "\t\t\t\t\tsource[i] = pinyin[i]\n",
    "\t\t\t\telif pinyin[i].startswith(source[i]) and pinyin[i][len(source[i]):] in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "\t\t\t\t\tpinyin[i] = source[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsource[i] = f\"[{source[i]}]\"\n",
    "\t\t\t\t\tpinyin[i] = f\"[{pinyin[i]}]\"\n",
    "\tdata.append({\n",
    "\t\t\"line\": line_number,\n",
    "\t\t\"text\": dataset[line_number][0],\n",
    "\t\t\"pinyin\": ' '.join(pinyin),\n",
    "\t\t\"source\": ' '.join(source),\n",
    "\t\t\"target\": ' '.join(pinyin)\n",
    "\t})\n",
    "with open('need-to-fix.json', 'w', encoding='utf-8') as f:\n",
    "\tf.write(json.dumps(data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"need-to-fix.json\", \"r\", encoding='utf-8') as f:\n",
    "\tjsondata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondata.sort(key=lambda x: x[\"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'line': 13, 'text': '高油价将对国际关系的互动，产生某种微妙或带有务实倾向的影响。', 'pinyin': 'gao1 you2 jia4 jiang1 dui4 guo2 ji4 guan1 [xi4] de hu4 dong4 chan3 sheng1 [mou3] zhong3 wei1 miao4 huo4 dai4 you3 wu4 shi2 qing1 xiang4 de [ying3] xiang3', 'source': 'gao1 you2 jia4 jiang1 dui4 guo2 ji4 guan1 [xi5] de hu4 dong4 chan3 sheng1 [mou2] zhong3 wei1 miao4 huo4 dai4 you3 wu4 shi2 qing1 xiang4 de [ying2] xiang3', 'target': 'gao1 you2 jia4 jiang1 dui4 guo2 ji4 guan1 [xi4] de hu4 dong4 chan3 sheng1 [mou2] zhong3 wei1 miao4 huo4 dai4 you3 wu4 shi2 qing1 xiang4 de [ying2] xiang3'}\n",
      "(13, 'gao1 you2 jia4 jiang1 dui4 guo2 ji4 guan1 xi4 de hu4 dong4 chan3 sheng1 mou3 zhong3 wei1 miao4 huo4 dai4 you3 wu4 shi2 qing1 xiang4 de ying3 xiang3')\n"
     ]
    }
   ],
   "source": [
    "print(jsondata[10])\n",
    "print(need_to_fixed[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_need_tofixed = need_to_fixed.copy()\n",
    "for i in range(len(jsondata)):\n",
    "\tif jsondata[i][\"line\"] <= 174:\n",
    "\t\ttarget = jsondata[i][\"target\"]\n",
    "\telse:\n",
    "\t\ttarget = ' '.join([ x[:-1] if x.endswith('5') else x for x in jsondata[i][\"source\"].split(' ') ])\n",
    "\ttarget = target.replace('[','').replace(']','')\n",
    "\tnew_need_tofixed[i] = (new_need_tofixed[i][0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69,\n",
       " 'zuo2 tian1 de mi2 wu4 he2 reng2 ran2 tuan1 ji2 bu2 guo4 che1 liang4 yi3 jing1 neng2 gou4 fei1 kuai4 de tong1 guo4')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_need_tofixed[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('躺在急救担架上的男子双目紧闭，头发散发出一股烧焦的味道。',\n",
       "  'tang3 zai4 ji2 jiu4 dan1 jia4 shang4 de nan2 zi shuang1 mu4 jin3 bi4 tou2 fa4 san4 fa1 chu1 yi4 gu3 shao1 jiao1 de wei4 dao4'),\n",
       " ('工业园区是承接产业转移、加速产业集聚、培育产业集群的主要载体。',\n",
       "  'gong1 ye4 yuan2 qu1 shi4 cheng2 jie1 chan3 ye4 zhuan3 yi2 jia1 su4 chan3 ye4 ji2 ju4 pei2 yu4 chan3 ye4 ji2 qun2 de zhu3 yao4 zai4 ti3'),\n",
       " ('那一刻，我才真正的懂你，就像懂我现在的自己。',\n",
       "  'na4 yi2 ke4 wo3 cai2 zhen1 zheng4 de dong2 ni3 jiu4 xiang4 dong3 wo3 xian4 zai4 de zi4 ji3'),\n",
       " ('由于列车长时间停靠，车厢内的空气越来越“闷”。',\n",
       "  'you2 yu2 lie4 che1 zhang3 shi2 jian1 ting2 kao4 che1 xiang1 nei4 de kong1 qi4 yue4 lai2 yue4 men1'),\n",
       " ('但如果按车队规模，一嗨数千辆车的量级绝对算不上最大。',\n",
       "  'dan4 ru2 guo3 an4 che1 dui4 gui1 mo2 yi1 hai1 shu4 qian1 liang4 che1 de liang4 ji2 jue2 dui4 suan4 bu2 shang4 zui4 da4')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected = dataset.copy()\n",
    "for (line_number, phome) in new_need_tofixed:\n",
    "\tcorrected[line_number] = (corrected[line_number][0], phome)\n",
    "for (line_number, phome) in auto_fixed:\n",
    "\tcorrected[line_number] = (corrected[line_number][0], phome)\n",
    "corrected[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"assets/text/mandarin_train_partial_clean.txt\", \"w\", encoding='utf-8') as f:\n",
    "\tfor (line, pinyin) in corrected:\n",
    "\t\tf.write(line + \"\\n\" + pinyin + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicelab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
