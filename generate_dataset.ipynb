{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 13:49:38,448 - modelscope - INFO - PyTorch version 2.3.1+cu121 Found.\n",
      "2025-02-23 13:49:38,451 - modelscope - INFO - Loading ast index from C:\\Users\\CHENHAOYUAN\\.cache\\modelscope\\ast_indexer\n",
      "2025-02-23 13:49:38,669 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 553a05bea23a95025342c8774cbd7108 and a total number of 980 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to import ttsfrd, use WeTextProcessing instead\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "sys.path.append(R\"D:\\GITHUB\\FunAudioLLM-APP\\cosyvoice\")\n",
    "sys.path.append(R\"D:\\GITHUB\\FunAudioLLM-APP\\cosyvoice\\third_party\\Matcha-TTS\")\n",
    "\n",
    "from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2\n",
    "from cosyvoice.utils.file_utils import load_wav\n",
    "from cosyvoice.utils.common import set_all_random_seed\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\diffusers\\models\\lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "2025-02-23 13:49:58,354 INFO input frame rate=25\n",
      "d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2025-02-23 13:50:00,398 WETEXT INFO building fst for zh_normalizer ...\n",
      "2025-02-23 13:50:00,398 INFO building fst for zh_normalizer ...\n",
      "2025-02-23 13:50:24,821 WETEXT INFO done\n",
      "2025-02-23 13:50:24,821 INFO done\n",
      "2025-02-23 13:50:24,822 WETEXT INFO fst path: d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\zh_tn_tagger.fst\n",
      "2025-02-23 13:50:24,822 INFO fst path: d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\zh_tn_tagger.fst\n",
      "2025-02-23 13:50:24,823 WETEXT INFO           d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\zh_tn_verbalizer.fst\n",
      "2025-02-23 13:50:24,823 INFO           d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\zh_tn_verbalizer.fst\n",
      "2025-02-23 13:50:24,831 WETEXT INFO found existing fst: d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\en_tn_tagger.fst\n",
      "2025-02-23 13:50:24,831 INFO found existing fst: d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\en_tn_tagger.fst\n",
      "2025-02-23 13:50:24,832 WETEXT INFO                     d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\en_tn_verbalizer.fst\n",
      "2025-02-23 13:50:24,832 INFO                     d:\\anaconda3\\envs\\cosyvoice\\lib\\site-packages\\tn\\en_tn_verbalizer.fst\n",
      "2025-02-23 13:50:24,832 WETEXT INFO skip building fst for en_normalizer ...\n",
      "2025-02-23 13:50:24,832 INFO skip building fst for en_normalizer ...\n"
     ]
    }
   ],
   "source": [
    "cosyvoice = CosyVoice2(R'D:\\GITHUB\\FunAudioLLM-APP\\cosyvoice\\pretrained_models\\CosyVoice2-0.5B', load_jit=False, load_trt=False, fp16=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载音频\n",
    "需要手动标记一下音频的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_audio = load_wav(R'D:\\GITHUB\\OpenVoice\\inputs\\train\\tvboy1_denoised.wav', 16000)\n",
    "prompt_text = \"两个或者三个吧，嗯肚子很胀，就是，有点，嗯，有时候会吐的\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从A到B的计划需要C和D的配合，以确保E可以成功执行。', '你从F到G的过程中，H的支持是不可缺少的，尤其是在I阶段。', '在项目进行中，J和K的合作将直接影响C的效率。', '如果你想提高L到M的速度，N的调整将非常重要。', '在这次活动中，O的出现为P带来了更大的机会。']\n",
      "Got dataset:  21\n",
      "Output folder:  ./assets/raw_dataset/tvboy_denoised_mandarin_letter_seed34751218\n",
      "Using seed:  34751218\n"
     ]
    }
   ],
   "source": [
    "batch = 4 # doesn't work at this moment\n",
    "output_dir = \"./assets/raw_dataset/tvboy_denoised_mandarin_letter_seed34751218\"\n",
    "seed = 34751218\n",
    "\n",
    "# 以下选一个\n",
    "\n",
    "## 普通话\n",
    "input_txts = \"./assets/text/withLetter.txt\"\n",
    "cross_lang = \"\"\n",
    "skip_line = 0\n",
    "\n",
    "## 粤语\n",
    "# input_txts = \"./cantonese.txt\"\n",
    "# cross_lang = \"粤语\"\n",
    "\n",
    "# ！！下面的不要动\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir, exist_ok=True)\n",
    "with open(input_txts, 'r', encoding='utf-8') as f:\n",
    "\tlines = f.readlines()\n",
    "\tinput_text_lines = []\n",
    "\tfor i in range(0, len(lines), skip_line+1):\n",
    "\t\tline = lines[i].strip()\n",
    "\t\tif line == \"\": continue\n",
    "\t\tinput_text_lines.append(line)\n",
    "\tprint(input_text_lines[:5])\n",
    "\tprint(\"Got dataset: \", len(input_text_lines))\n",
    "\tdef input_generator():\n",
    "\t\tfor i in range(0, len(input_text_lines), batch):\n",
    "\t\t\tyield input_text_lines[i:min(i+batch, len(input_text_lines))]\n",
    "set_all_random_seed(seed)\n",
    "print(\"Output folder: \", output_dir)\n",
    "print(\"Using seed: \", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zero infer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 16:18:17,891 INFO synthesis text 从A到B需要C来维持，然而若D到E然后从F到G就会让H达不到I隔壁的J。\n",
      "2025-02-23 16:18:26,125 INFO yield speech len 11.8, rtf 0.6978050935066352\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"从A到B需要C来维持，然而若D到E然后从F到G就会让H达不到I隔壁的J。\" #K、L、M、N、O、P、Q、R、S、T、U、V、W、X、Y、Z。\" # input_text_lines[0]\n",
    "def zero_infer():\n",
    "\tprint(\"Using zero infer.\")\n",
    "\tret = list(cosyvoice.inference_zero_shot(sample_text, prompt_text, prompt_audio, stream=False))[0]\n",
    "\ttorchaudio.save(\"zero_infer.wav\", ret['tts_speech'], cosyvoice.sample_rate)\n",
    "def cross_infer():\n",
    "\tprint(\"Using cross shot to \" + cross_lang + \".\")\n",
    "\tinstruct_text = f\"用{cross_lang}说这句话\"\n",
    "\tret = list(cosyvoice.inference_instruct2(sample_text, instruct_text, prompt_audio, stream=False))[0]\n",
    "\ttorchaudio.save(\"cross_infer.wav\", ret['tts_speech'], cosyvoice.sample_rate)\n",
    "if cross_lang == \"\":\n",
    "\tzero_infer()\n",
    "else:\n",
    "\tcross_infer()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zero shot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:57:28,285 INFO synthesis text 从A到B的计划需要C和D的配合，以确保E可以成功执行。\n",
      "2025-02-23 17:57:33,769 INFO yield speech len 7.08, rtf 0.7744277937937591\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:57:34,374 INFO synthesis text 你从F到G的过程中，H的支持是不可缺少的，尤其是在I阶段。\n",
      "2025-02-23 17:57:41,723 INFO yield speech len 8.64, rtf 0.8506336697825678\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:57:42,318 INFO synthesis text 在项目进行中，J和K的合作将直接影响C的效率。\n",
      "2025-02-23 17:57:47,240 INFO yield speech len 6.68, rtf 0.7368446467165461\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:57:47,840 INFO synthesis text 如果你想提高L到M的速度，N的调整将非常重要。\n",
      "2025-02-23 17:57:53,492 INFO yield speech len 7.68, rtf 0.735934761663278\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.24s/it]\n",
      "1it [00:25, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:57:54,092 INFO synthesis text 在这次活动中，O的出现为P带来了更大的机会。\n",
      "2025-02-23 17:57:59,432 INFO yield speech len 7.2, rtf 0.741611917813619\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:00,030 INFO synthesis text 通过Q的努力，R的效果得到了S的验证，T的方向也更明确。\n",
      "2025-02-23 17:58:04,881 INFO yield speech len 6.48, rtf 0.7487641072567598\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:05,480 INFO synthesis text 为了完成U任务，我们需要从V到W的精确步骤。\n",
      "2025-02-23 17:58:09,920 INFO yield speech len 5.44, rtf 0.8161699070649988\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:10,521 INFO synthesis text 在评估过程中，X和Y的比较为Z提供了新的解决方案。\n",
      "2025-02-23 17:58:14,740 INFO yield speech len 5.44, rtf 0.7755555650767157\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
      "2it [00:47, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:15,341 INFO synthesis text 你能否从A到B顺利过渡，取决于C的最终确认。\n",
      "2025-02-23 17:58:20,415 INFO yield speech len 6.88, rtf 0.737520948398945\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:21,008 INFO synthesis text 如果你希望提高D到E的质量，必须增加F的投资。\n",
      "2025-02-23 17:58:25,486 INFO yield speech len 6.16, rtf 0.7271578172584633\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:26,082 INFO synthesis text 在此项目中，G与H的协作是关键，I的反馈帮助J改进。\n",
      "2025-02-23 17:58:32,240 INFO yield speech len 8.48, rtf 0.7262026082794621\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:32,844 INFO synthesis text 在分析过程中，K和L之间的关系让N得到了优化。\n",
      "2025-02-23 17:58:37,398 INFO yield speech len 5.96, rtf 0.7639401311042325\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.14s/it]\n",
      "3it [01:09, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:37,997 INFO synthesis text 你可以通过M和O的融合，提升P的效率，特别是在Q的环节。\n",
      "2025-02-23 17:58:44,825 INFO yield speech len 9.64, rtf 0.7083915823228131\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:45,423 INFO synthesis text 如果从R到S的设计能够顺利完成，T的成果将会得到验证。\n",
      "2025-02-23 17:58:51,031 INFO yield speech len 7.76, rtf 0.7227014020546195\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:51,628 INFO synthesis text 我们需要通过U、V、W三个步骤来确保从X到Y的转变。\n",
      "2025-02-23 17:58:57,515 INFO yield speech len 8.08, rtf 0.7286460387824786\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:58:58,113 INFO synthesis text B的改进使得从Z到U的过渡更加流畅，G也得到了优化。\n",
      "2025-02-23 17:59:05,330 INFO yield speech len 10.4, rtf 0.6939370586321904\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.80s/it]\n",
      "4it [01:37, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:59:05,941 INFO synthesis text 如果U的调整可以顺利完成，那么W的效果将会大幅提升。\n",
      "2025-02-23 17:59:11,143 INFO yield speech len 7.04, rtf 0.7388458333232186\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:59:11,740 INFO synthesis text 在这个过程中，从I到V的变化将直接影响到C的执行。\n",
      "2025-02-23 17:59:17,382 INFO yield speech len 7.88, rtf 0.7159528695992406\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:59:17,979 INFO synthesis text 通过J的参与，K到H的过渡期得到了有效的缩短。\n",
      "2025-02-23 17:59:22,622 INFO yield speech len 6.36, rtf 0.7299135316093013\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:59:23,226 INFO synthesis text 你需要从O到Y的每一步都做到精准，以确保C的达成。\n",
      "2025-02-23 17:59:28,107 INFO yield speech len 6.64, rtf 0.7351493260946619\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.47s/it]\n",
      "5it [02:00, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0223)\n",
      "max value is  tensor(1.0314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 17:59:28,705 INFO synthesis text 从A到B需要C来维持，然而若D到E然后从F到G就会让H达不到I隔壁的J。\n",
      "2025-02-23 17:59:35,343 INFO yield speech len 9.32, rtf 0.7122266446060377\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.22s/it]\n",
      "6it [02:07, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SkipExisted = False\n",
    "def zero_shot():\n",
    "\tprint(\"Using zero shot.\")\n",
    "\tfor idx, input_data in enumerate(tqdm(input_generator())):\n",
    "\t\tfor subidx, data in enumerate(input_data):\n",
    "\t\t\tglobal_idx = idx * batch + subidx + 1\n",
    "\t\t\tfilename = os.path.join(output_dir, f\"{global_idx}.wav\")\n",
    "\t\t\tif SkipExisted and os.path.exists(filename):\n",
    "\t\t\t\tprint(\"Skip \", filename)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tret = list(cosyvoice.inference_zero_shot(data, prompt_text, prompt_audio, stream=False))[0]\n",
    "\t\t\ttorchaudio.save(filename, ret['tts_speech'], cosyvoice.sample_rate)\n",
    "def cross_shot():\n",
    "\tprint(\"Using cross shot to \" + cross_lang + \".\")\n",
    "\tinstruct_text = f\"用{cross_lang}说这句话\"\n",
    "\tfor idx, input_data in enumerate(tqdm(input_generator())):\n",
    "\t\tfor subidx, data in enumerate(input_data):\n",
    "\t\t\tglobal_idx = idx * batch + subidx + 1\n",
    "\t\t\tfilename = os.path.join(output_dir, f\"{global_idx}.wav\")\n",
    "\t\t\tif SkipExisted and os.path.exists(filename):\n",
    "\t\t\t\tprint(\"Skip \", filename)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tret = list(cosyvoice.inference_instruct2(data, instruct_text, prompt_audio, stream=False))[0]\n",
    "\t\t\ttorchaudio.save(filename, ret['tts_speech'], cosyvoice.sample_rate)\n",
    "if cross_lang == \"\":\n",
    "\tzero_shot()\n",
    "else:\n",
    "\tcross_shot()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
